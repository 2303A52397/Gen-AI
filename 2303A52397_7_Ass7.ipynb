{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPloELOkPuE5Oz4OGE+g6um",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52397/Gen-AI/blob/main/2303A52397_7_Ass7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_data():\n",
        "    # Dummy function: Replace with actual dataset loading\n",
        "    # Normalize feature values and one-hot encode labels if necessary\n",
        "    # This is a placeholder, replace with your actual data loading and preprocessing logic\n",
        "    X_train = np.array([[1, 2], [3, 4]])\n",
        "    y_train = np.array([0, 1])\n",
        "    X_test = np.array([[5, 6], [7, 8]])\n",
        "    y_test = np.array([1, 0])\n",
        "\n",
        "    return X_train, y_train, X_test, y_test # Return the data as a tuple\n",
        "\n",
        "X_train, y_train, X_test, y_test = load_data()"
      ],
      "metadata": {
        "id": "w0PdokptmbeI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "6W-i37HQm0vM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights():\n",
        "    np.random.seed(42)\n",
        "    W1 = np.random.randn(X_train.shape[1], 8) * 0.1\n",
        "    b1 = np.zeros((1, 8))\n",
        "    W2 = np.random.randn(8, 16) * 0.1\n",
        "    b2 = np.zeros((1, 16))\n",
        "    W3 = np.random.randn(16, 20) * 0.1\n",
        "    b3 = np.zeros((1, 20))\n",
        "    W4 = np.random.randn(20, 10) * 0.1\n",
        "    b4 = np.zeros((1, 10))\n",
        "    W5 = np.random.randn(10, 1) * 0.1  # Output layer (Binary classification)\n",
        "    b5 = np.zeros((1, 1))\n",
        "    return W1, b1, W2, b2, W3, b3, W4, b4, W5, b5\n",
        "\n",
        "W1, b1, W2, b2, W3, b3, W4, b4, W5, b5 = initialize_weights()"
      ],
      "metadata": {
        "id": "hu_-GoFDnAHs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(X):\n",
        "    global W1, b1, W2, b2, W3, b3, W4, b4, W5, b5\n",
        "\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = relu(Z2)\n",
        "    Z3 = np.dot(A2, W3) + b3\n",
        "    A3 = relu(Z3)\n",
        "    Z4 = np.dot(A3, W4) + b4\n",
        "    A4 = relu(Z4)\n",
        "    Z5 = np.dot(A4, W5) + b5\n",
        "    A5 = sigmoid(Z5)\n",
        "\n",
        "    cache = {\"A1\": A1, \"Z1\": Z1, \"A2\": A2, \"Z2\": Z2, \"A3\": A3, \"Z3\": Z3, \"A4\": A4, \"Z4\": Z4, \"A5\": A5, \"Z5\": Z5}\n",
        "    return A5, cache"
      ],
      "metadata": {
        "id": "nI2v3ao3nB-j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(X, y, cache, lr=0.01):\n",
        "    global W1, b1, W2, b2, W3, b3, W4, b4, W5, b5\n",
        "\n",
        "    A1, Z1, A2, Z2, A3, Z3, A4, Z4, A5, Z5 = cache[\"A1\"], cache[\"Z1\"], cache[\"A2\"], cache[\"Z2\"], cache[\"A3\"], cache[\"Z3\"], cache[\"A4\"], cache[\"Z4\"], cache[\"A5\"], cache[\"Z5\"]\n",
        "\n",
        "    # Compute gradients\n",
        "    dZ5 = A5 - y\n",
        "    dW5 = np.dot(A4.T, dZ5) / X.shape[0]\n",
        "    db5 = np.sum(dZ5, axis=0, keepdims=True) / X.shape[0]\n",
        "\n",
        "    dZ4 = np.dot(dZ5, W5.T) * relu_derivative(Z4)\n",
        "    dW4 = np.dot(A3.T, dZ4) / X.shape[0]\n",
        "    db4 = np.sum(dZ4, axis=0, keepdims=True) / X.shape[0]\n",
        "\n",
        "    dZ3 = np.dot(dZ4, W4.T) * relu_derivative(Z3)\n",
        "    dW3 = np.dot(A2.T, dZ3) / X.shape[0]\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True) / X.shape[0]\n",
        "\n",
        "    dZ2 = np.dot(dZ3, W3.T) * relu_derivative(Z2)\n",
        "    dW2 = np.dot(A1.T, dZ2) / X.shape[0]\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / X.shape[0]\n",
        "\n",
        "    dZ1 = np.dot(dZ2, W2.T) * relu_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1) / X.shape[0]\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / X.shape[0]\n",
        "\n",
        "    # Update weights\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    W3 -= lr * dW3\n",
        "    b3 -= lr * db3\n",
        "    W4 -= lr * dW4\n",
        "    b4 -= lr * db4\n",
        "    W5 -= lr * dW5\n",
        "    b5 -= lr * db5"
      ],
      "metadata": {
        "id": "Z4rshZoinHWs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(X, y):\n",
        "    A5, _ = forward_pass(X)\n",
        "    predictions = (A5 > 0.5).astype(int)  # Convert probabilities to binary values\n",
        "    actual = y.astype(int)\n",
        "    return np.mean(predictions == actual)\n",
        "\n",
        "train_acc = evaluate(X_train, y_train)\n",
        "test_acc = evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Training Accuracy: {train_acc * 100:.2f}%\")\n",
        "print(f\"Testing Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpIjTWwznMbp",
        "outputId": "bbc2e5d8-719d-4b20-a338-ac5a0715ce27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 50.00%\n",
            "Testing Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix(y_true, y_pred):\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1-Score: {f1_score:.2f}\")\n",
        "    print(f\"Confusion Matrix:\\n [[{TN}, {FP}],\\n [{FN}, {TP}]]\")\n",
        "\n",
        "y_pred = (forward_pass(X_test)[0] > 0.5).astype(int)\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAF32QhonTzN",
        "outputId": "d2f1a641-1379-4669-ff5f-a4f96fb1718c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.00\n",
            "Recall: 0.00\n",
            "F1-Score: 0.00\n",
            "Confusion Matrix:\n",
            " [[2, 0],\n",
            " [2, 0]]\n"
          ]
        }
      ]
    }
  ]
}